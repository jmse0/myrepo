{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_sjm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmse0/myrepo/blob/master/Bert_sjm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrhPRDPgLWSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "148d9079-d8d3-4e59-b2d8-4f4606cb261b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/silverkhan/krDataScience/master/ml02/CRSE_df.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-06 05:36:40--  https://raw.githubusercontent.com/silverkhan/krDataScience/master/ml02/CRSE_df.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 834462 (815K) [application/octet-stream]\n",
            "Saving to: ‘CRSE_df.pkl’\n",
            "\n",
            "CRSE_df.pkl         100%[===================>] 814.90K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-08-06 05:36:41 (11.0 MB/s) - ‘CRSE_df.pkl’ saved [834462/834462]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ZIOdndrk7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "83abe499-82f7-4a7a-fe81-137f80185148"
      },
      "source": [
        "# !pip install bert\n",
        "!pip install bert-for-tf2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.7MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30315 sha256=e26a93019aa7f6a18c7cb5c053832b18efa5cad4206fe19c442e1ed8e4effa8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=263ef7eae77272af6c6d51668175f0982c2c3a6d8ae7d8b2ab6eb0e3fe011109\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=b3c0b8a67630099f60702014f6e1c59ac4fec9bf95ffecdcfa12350daea499c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSQuGebgr1rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "351b25c1-4290-48de-842b-fba5ae869653"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Activation, LSTM, SimpleRNN, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import bert\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from bert import bert_tokenization\n",
        "import time\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.3.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEL8u-Ear3Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#컬럼명\n",
        "topicCol_char = \"CRSE_CL\"\n",
        "labelCol_char = \"STD_CD\"\n",
        "padIntCol_char = \"PADDED_NM\"\n",
        "crtYM_char = \"CRT_YM\"\n",
        "# 변수\n",
        "testSplit_char = \"2020.05\"\n",
        "# Path 정의\n",
        "curDataPath_char = \"https://raw.githubusercontent.com/silverkhan/krDataScience/master/ml02/CRSE_df_0803.pkl\"\n",
        "# pastDataPath_char = \"https://raw.githubusercontent.com/silverkhan/krDataScience/master/ml02/PAST_df.pkl\"\n",
        "curRaw_df = pd.read_pickle(curDataPath_char)\n",
        "# pastRaw_df = pd.read_pickle(pastDataPath_char)\n",
        "# Testset 정의\n",
        "rawTest_df = curRaw_df.query(crtYM_char + \" >= \" + testSplit_char).copy()\n",
        "rawTrain_df = curRaw_df.query(crtYM_char + \" < \" + testSplit_char).copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH1xM8fOLls_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "392cee7b-b95f-4716-8307-405e7d58c1a2"
      },
      "source": [
        "print(curRaw_df.shape)\n",
        "print(rawTest_df.shape)\n",
        "print(rawTrain_df.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3725, 8)\n",
            "(106, 8)\n",
            "(3619, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHBluBm9NBtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkBtw = pd.merge(check_raw, check_train, on = 'CRT_YN')\n",
        "# checkBtw[\"check\"] = checkBtw['rawFrq'] == checkBtw[\"trainFrq\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcH73UslNaDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b52ab558-3974-40d6-e1b9-35ee35620a3b"
      },
      "source": [
        "# checkBtw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRT_YN</th>\n",
              "      <th>rawFrq</th>\n",
              "      <th>trainFrq</th>\n",
              "      <th>check</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017.01</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017.02</td>\n",
              "      <td>163</td>\n",
              "      <td>163</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017.03</td>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017.04</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017.05</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017.06</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017.07</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017.08</td>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017.09</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017.10</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2017.11</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2017.12</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018.01</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2018.02</td>\n",
              "      <td>102</td>\n",
              "      <td>102</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2018.03</td>\n",
              "      <td>124</td>\n",
              "      <td>124</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2018.04</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2018.05</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2018.06</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2018.07</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2018.08</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2018.09</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2018.10</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2018.11</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2018.12</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2019.01</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2019.02</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2019.03</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2019.04</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2019.05</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2019.06</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2019.07</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2019.08</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2019.09</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019.10</td>\n",
              "      <td>348</td>\n",
              "      <td>348</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019.11</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019.12</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2020.01</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2020.02</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2020.03</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2020.04</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     CRT_YN  rawFrq  trainFrq  check\n",
              "0   2017.01      75        75   True\n",
              "1   2017.02     163       163   True\n",
              "2   2017.03     113       113   True\n",
              "3   2017.04      79        79   True\n",
              "4   2017.05      63        63   True\n",
              "5   2017.06      58        58   True\n",
              "6   2017.07      27        27   True\n",
              "7   2017.08      62        62   True\n",
              "8   2017.09      56        56   True\n",
              "9   2017.10      54        54   True\n",
              "10  2017.11      36        36   True\n",
              "11  2017.12      14        14   True\n",
              "12  2018.01      40        40   True\n",
              "13  2018.02     102       102   True\n",
              "14  2018.03     124       124   True\n",
              "15  2018.04      65        65   True\n",
              "16  2018.05     121       121   True\n",
              "17  2018.06      79        79   True\n",
              "18  2018.07     125       125   True\n",
              "19  2018.08      57        57   True\n",
              "20  2018.09      57        57   True\n",
              "21  2018.10      52        52   True\n",
              "22  2018.11      90        90   True\n",
              "23  2018.12      56        56   True\n",
              "24  2019.01      20        20   True\n",
              "25  2019.02     166       166   True\n",
              "26  2019.03     191       191   True\n",
              "27  2019.04     125       125   True\n",
              "28  2019.05     105       105   True\n",
              "29  2019.06     137       137   True\n",
              "30  2019.07     109       109   True\n",
              "31  2019.08     175       175   True\n",
              "32  2019.09     100       100   True\n",
              "33  2019.10     348       348   True\n",
              "34  2019.11      35        35   True\n",
              "35  2019.12      69        69   True\n",
              "36  2020.01      45        45   True\n",
              "37  2020.02      87        87   True\n",
              "38  2020.03      46        46   True\n",
              "39  2020.04      93        93   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h98OUAp_2ByN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "99106bf5-cdad-487d-a8b2-819fbcf79256"
      },
      "source": [
        "display(curRaw_df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRSE_CD</th>\n",
              "      <th>CRSE_NM</th>\n",
              "      <th>CRSE_BERT</th>\n",
              "      <th>CRSE_CL</th>\n",
              "      <th>PADDED_NM</th>\n",
              "      <th>CRT_YM</th>\n",
              "      <th>STD_CAT</th>\n",
              "      <th>STD_CD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAAA009</td>\n",
              "      <td>(중앙회)5급신규직원입문과정(직무)</td>\n",
              "      <td>신규직원입문 직무</td>\n",
              "      <td>[신규, 직원, 입문, 직무]</td>\n",
              "      <td>[77, 69, 95, 148, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2018.12</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AABA096</td>\n",
              "      <td>하나로유통 세무회계 실무</td>\n",
              "      <td>하나로유통 세무회계 실무</td>\n",
              "      <td>[하나, 로, 유통, 세무, 회계, 실무]</td>\n",
              "      <td>[193, 28, 43, 92, 58, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2017.04</td>\n",
              "      <td>회계업무</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AABA097</td>\n",
              "      <td>협동조합전문가역량강화과정</td>\n",
              "      <td>협동조합전문가역량강화</td>\n",
              "      <td>[협동조합, 전문가, 역량, 강화]</td>\n",
              "      <td>[339, 19, 89, 106, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2018.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPA010</td>\n",
              "      <td>농축협 순회검사역 과정</td>\n",
              "      <td>농축협 순회검사역 과정</td>\n",
              "      <td>[농, 축협, 순회, 검사역, 과정]</td>\n",
              "      <td>[8, 26, 2481, 1385, 47, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AD3A001</td>\n",
              "      <td>(생명) 직무전문가 육성체계 및 교육프로그램 사례발표회</td>\n",
              "      <td>직무전문가 육성체계 및 교육프로그램 사례발표회</td>\n",
              "      <td>[직무, 전문가, 육성, 체계, 및, 교육, 프로그램, 사례, 발표회]</td>\n",
              "      <td>[148, 19, 713, 764, 14, 9, 737, 62, 890, 0, 0,...</td>\n",
              "      <td>2018.04</td>\n",
              "      <td>강사양성과정</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>LSDM001</td>\n",
              "      <td>상호금융 리더를 위한 DT-AI 인사이트</td>\n",
              "      <td>상호금융 리더를 위한 DTAI 인사이트</td>\n",
              "      <td>[상호, 금융, 리더, 를, 위한, DTAI, 인, 사이트]</td>\n",
              "      <td>[184, 7, 70, 12, 13, 3442, 80, 846, 0, 0, 0, 0...</td>\n",
              "      <td>2019.08</td>\n",
              "      <td>산업동향</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3721</th>\n",
              "      <td>LSPM001</td>\n",
              "      <td>빅데이터를 활용한 CRM고객관리</td>\n",
              "      <td>빅데이터를 한 CRM고객관리</td>\n",
              "      <td>[빅, 데이터, 를, 한, CRM, 고객, 관리]</td>\n",
              "      <td>[125, 59, 12, 22, 377, 41, 11, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2019.05</td>\n",
              "      <td>영업마케팅</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3722</th>\n",
              "      <td>LTBK001</td>\n",
              "      <td>재무리스크 측정과 관리실무</td>\n",
              "      <td>재무리스크 측정과 관리실무</td>\n",
              "      <td>[재무, 리스크, 측정, 과, 관리, 실무]</td>\n",
              "      <td>[86, 143, 1141, 21, 11, 4, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.10</td>\n",
              "      <td>금융리스크</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3723</th>\n",
              "      <td>LTDK001</td>\n",
              "      <td>북한비즈니스</td>\n",
              "      <td>북한비즈니스</td>\n",
              "      <td>[북한, 비즈니스]</td>\n",
              "      <td>[2979, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>2020.04</td>\n",
              "      <td>금융교육과정</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3724</th>\n",
              "      <td>LUPD001</td>\n",
              "      <td>영업점관리자 사이버교육</td>\n",
              "      <td>영업점관리자 사이버교육</td>\n",
              "      <td>[영업, 점, 관리자, 사이버, 교육]</td>\n",
              "      <td>[102, 226, 99, 146, 9, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>2020.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3725 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRSE_CD                         CRSE_NM  ... STD_CAT STD_CD\n",
              "0     AAAA009             (중앙회)5급신규직원입문과정(직무)  ...    직원일반      4\n",
              "1     AABA096                   하나로유통 세무회계 실무  ...    회계업무      7\n",
              "2     AABA097                   협동조합전문가역량강화과정  ...    직원일반      4\n",
              "3     AAPA010                    농축협 순회검사역 과정  ...    직원일반      4\n",
              "4     AD3A001  (생명) 직무전문가 육성체계 및 교육프로그램 사례발표회  ...  강사양성과정     41\n",
              "...       ...                             ...  ...     ...    ...\n",
              "3720  LSDM001          상호금융 리더를 위한 DT-AI 인사이트  ...    산업동향      1\n",
              "3721  LSPM001               빅데이터를 활용한 CRM고객관리  ...   영업마케팅      2\n",
              "3722  LTBK001                  재무리스크 측정과 관리실무  ...   금융리스크     22\n",
              "3723  LTDK001                          북한비즈니스  ...  금융교육과정     10\n",
              "3724  LUPD001                    영업점관리자 사이버교육  ...    직원일반      4\n",
              "\n",
              "[3725 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEhikQhwr6lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#7/30 삭제 labelCol_Num_char = \"['1',  '2',  '3',  '4',  '5',  '6',  '7',  '8',  '9',  '10',  '11',  '12',  '13',  '14',  '15',  '16',  '17',  '18',  '19',  '20',  '21',  '22',  '23',  '24',  '25',  '26',  '27',  '28',  '29',  '30',  '31',  '32',  '33',  '34',  '35',  '36',  '37',  '38',  '39',  '40',  '41',  '42',  '43',  '44',  '45',  '46',  '47',  '48',  '49',  '50',  '51',  '52', '53']\"\n",
        "# labelCol_Num_char = \"['1',  '2',  '3',  '4',  '5']\"\n",
        "#7/30 삭제 f_rawTest_df = rawTest_df.query(labelCol_char + \" in \" + labelCol_Num_char)\n",
        "#7/30 삭제 f_rawTrain_df = rawTrain_df.query(labelCol_char + \" in \" + labelCol_Num_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDDPFF0vMezv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = np.unique(rawTrain_df[labelCol_char], return_counts=True)\n",
        "# check_ori = pd.DataFrame(data = {labelCol_char:x[0], 'oriFrq':x[1]})\n",
        "#7/30 삭제 x = np.unique(f_rawTrain_df[labelCol_char], return_counts=True)\n",
        "#7/30 삭제 check_f = pd.DataFrame(data = {labelCol_char:x[0], 'fFrq':x[1]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_BdXgsbO7jH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b1c98e9-91ed-498e-c9b0-435def02cd8c"
      },
      "source": [
        "# checkBtw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRT_YN</th>\n",
              "      <th>rawFrq</th>\n",
              "      <th>trainFrq</th>\n",
              "      <th>check</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017.01</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017.02</td>\n",
              "      <td>163</td>\n",
              "      <td>163</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017.03</td>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017.04</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017.05</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017.06</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017.07</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2017.08</td>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2017.09</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2017.10</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2017.11</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2017.12</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018.01</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2018.02</td>\n",
              "      <td>102</td>\n",
              "      <td>102</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2018.03</td>\n",
              "      <td>124</td>\n",
              "      <td>124</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2018.04</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2018.05</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2018.06</td>\n",
              "      <td>79</td>\n",
              "      <td>79</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2018.07</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2018.08</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2018.09</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2018.10</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2018.11</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2018.12</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2019.01</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2019.02</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2019.03</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2019.04</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2019.05</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2019.06</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2019.07</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2019.08</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2019.09</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019.10</td>\n",
              "      <td>348</td>\n",
              "      <td>348</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019.11</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019.12</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2020.01</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2020.02</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2020.03</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2020.04</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     CRT_YN  rawFrq  trainFrq  check\n",
              "0   2017.01      75        75   True\n",
              "1   2017.02     163       163   True\n",
              "2   2017.03     113       113   True\n",
              "3   2017.04      79        79   True\n",
              "4   2017.05      63        63   True\n",
              "5   2017.06      58        58   True\n",
              "6   2017.07      27        27   True\n",
              "7   2017.08      62        62   True\n",
              "8   2017.09      56        56   True\n",
              "9   2017.10      54        54   True\n",
              "10  2017.11      36        36   True\n",
              "11  2017.12      14        14   True\n",
              "12  2018.01      40        40   True\n",
              "13  2018.02     102       102   True\n",
              "14  2018.03     124       124   True\n",
              "15  2018.04      65        65   True\n",
              "16  2018.05     121       121   True\n",
              "17  2018.06      79        79   True\n",
              "18  2018.07     125       125   True\n",
              "19  2018.08      57        57   True\n",
              "20  2018.09      57        57   True\n",
              "21  2018.10      52        52   True\n",
              "22  2018.11      90        90   True\n",
              "23  2018.12      56        56   True\n",
              "24  2019.01      20        20   True\n",
              "25  2019.02     166       166   True\n",
              "26  2019.03     191       191   True\n",
              "27  2019.04     125       125   True\n",
              "28  2019.05     105       105   True\n",
              "29  2019.06     137       137   True\n",
              "30  2019.07     109       109   True\n",
              "31  2019.08     175       175   True\n",
              "32  2019.09     100       100   True\n",
              "33  2019.10     348       348   True\n",
              "34  2019.11      35        35   True\n",
              "35  2019.12      69        69   True\n",
              "36  2020.01      45        45   True\n",
              "37  2020.02      87        87   True\n",
              "38  2020.03      46        46   True\n",
              "39  2020.04      93        93   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMPXO1TeP_Hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "f596853e-6a3e-4c07-a265-8a451fdc0ed4"
      },
      "source": [
        "# rawTrain_df[rawTrain_df.STD_CD == '52']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRSE_CD</th>\n",
              "      <th>CRSE_NM</th>\n",
              "      <th>CRSE_BERT</th>\n",
              "      <th>CRSE_CL</th>\n",
              "      <th>PADDED_NM</th>\n",
              "      <th>CRT_YM</th>\n",
              "      <th>STD_CAT</th>\n",
              "      <th>STD_CD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>BA3K001</td>\n",
              "      <td>기업금융RM단기과정</td>\n",
              "      <td>기업금융RM단기</td>\n",
              "      <td>[기업, 금융, RM, 단기]</td>\n",
              "      <td>[31, 7, 559, 493, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.10</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>BAPA047</td>\n",
              "      <td>영업본부 현장지원단 RM 기본교육(은행)</td>\n",
              "      <td>영업본부 현장지원단 RM 기본교육</td>\n",
              "      <td>[영업, 본부, 현장, 지원, 단, RM, 기본, 교육]</td>\n",
              "      <td>[102, 1518, 221, 424, 2607, 559, 51, 9, 0, 0, ...</td>\n",
              "      <td>2017.02</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>BAPA054</td>\n",
              "      <td>기업금융RM 단기과정(은행)</td>\n",
              "      <td>기업금융RM 단기</td>\n",
              "      <td>[기업, 금융, RM, 단기]</td>\n",
              "      <td>[31, 7, 559, 493, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2018.10</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>BIBA576</td>\n",
              "      <td>영업본부 RM심화과정(은행)</td>\n",
              "      <td>영업본부 RM심화</td>\n",
              "      <td>[영업, 본부, RM, 심화]</td>\n",
              "      <td>[102, 1518, 559, 183, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2017.08</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>BIBA590</td>\n",
              "      <td>기업금융 RM 기초(은행)</td>\n",
              "      <td>기업금융 RM 기초</td>\n",
              "      <td>[기업, 금융, RM, 기초]</td>\n",
              "      <td>[31, 7, 559, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>2018.01</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>BIBA598</td>\n",
              "      <td>농협은행 경기영업본부 RM 실습</td>\n",
              "      <td>농협은행 경기영업본부 RM 실습</td>\n",
              "      <td>[농협, 은행, 경기, 영업, 본부, RM, 실습]</td>\n",
              "      <td>[34, 154, 1428, 102, 1518, 559, 292, 0, 0, 0, ...</td>\n",
              "      <td>2018.01</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>BIPA014</td>\n",
              "      <td>영업본부 RM기본과정</td>\n",
              "      <td>영업본부 RM기본</td>\n",
              "      <td>[영업, 본부, RM, 기본]</td>\n",
              "      <td>[102, 1518, 559, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2018.01</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>BU3K014</td>\n",
              "      <td>기업금융RM고급과정</td>\n",
              "      <td>기업금융RM고급</td>\n",
              "      <td>[기업, 금융, RM, 고급]</td>\n",
              "      <td>[31, 7, 559, 202, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.10</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>FABA163</td>\n",
              "      <td>현장지원단 RM 기본교육(은행)</td>\n",
              "      <td>현장지원단 RM 기본교육</td>\n",
              "      <td>[현, 장지, 원단, RM, 기본, 교육]</td>\n",
              "      <td>[938, 5174, 2518, 559, 51, 9, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2017.02</td>\n",
              "      <td>RM교육</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRSE_CD                 CRSE_NM  ... STD_CAT STD_CD\n",
              "441   BA3K001              기업금융RM단기과정  ...    RM교육     52\n",
              "453   BAPA047  영업본부 현장지원단 RM 기본교육(은행)  ...    RM교육     52\n",
              "460   BAPA054         기업금융RM 단기과정(은행)  ...    RM교육     52\n",
              "696   BIBA576         영업본부 RM심화과정(은행)  ...    RM교육     52\n",
              "707   BIBA590          기업금융 RM 기초(은행)  ...    RM교육     52\n",
              "715   BIBA598       농협은행 경기영업본부 RM 실습  ...    RM교육     52\n",
              "731   BIPA014             영업본부 RM기본과정  ...    RM교육     52\n",
              "927   BU3K014              기업금융RM고급과정  ...    RM교육     52\n",
              "1254  FABA163       현장지원단 RM 기본교육(은행)  ...    RM교육     52\n",
              "\n",
              "[9 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtBCLkYPm_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "949f21e8-780c-45f5-ab12-4f7015ad8bdf"
      },
      "source": [
        "# print(check_ori.shape)\n",
        "# print(check_f.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(52, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIuGGdTYlDFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ['1',  '2',  '3',  '4',  '5',  '6',  '7',  '8',  '9',  '10',  '11',  '12',  '13',  '14',  '15',  '16',  '17',  '18',  '19',  '20',  '21',  '22',  '23',  '24',  '25',  '26',  '27',  '28',  '29',  '30',  '31',  '32',  '33',  '34',  '35',  '36',  '37',  '38',  '39',  '40',  '41',  '42',  '43',  '44',  '45',  '46',  '47',  '48',  '49',  '50',  '51',  '52']\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8As3XSAr6ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LoadingData():\n",
        "\n",
        "    def __init__(self):\n",
        "      self.train_data_frame = rawTrain_df.copy()\n",
        "\n",
        "      # self.curRaw_category = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/labelMst.txt\", sep='\\t')\n",
        "\n",
        "      self.curRaw_category = curRaw_df[['STD_CAT', 'STD_CD']].drop_duplicates(['STD_CAT'])\n",
        "      self.cat_to_intent = self.curRaw_category.set_index('STD_CAT').T.to_dict('records')[0]\n",
        "\n",
        "      # curRaw_category = curRaw_df[['STD_CAT', 'STD_CD']].drop_duplicates(['STD_CAT'])\n",
        "      # self.cat_to_intent = curRaw_category.set_index('STD_CAT').T.to_dict('records')[0]\n",
        "      # self.cat_to_intent = {k : int(v) for k, v in self.cat_to_intent.items()}\n",
        "      self.intent_to_cat = {self.cat_to_intent[x]:x for x in self.cat_to_intent}\n",
        "\n",
        "      self.train_data_frame = self.train_data_frame.rename(columns={'CRSE_BERT' : 'id', 'CRSE_NM' : 'query', 'STD_CAT' : 'intent','STD_CD' : 'category'})\n",
        "      self.train_data_frame = self.train_data_frame[['id','query','intent','category']]\n",
        "      self.train_data_frame['category'] = pd.to_numeric(self.train_data_frame['category'])\n",
        "\n",
        "      self.validation_data_frame = rawTest_df.copy()\n",
        "      self.validation_data_frame = self.validation_data_frame.rename(columns={'CRSE_BERT' : 'id', 'CRSE_NM' : 'query', 'STD_CAT' : 'intent','STD_CD' : 'category'})\n",
        "      self.validation_data_frame = self.validation_data_frame[['id','query','intent','category']]\n",
        "      self.validation_data_frame['category'] = pd.to_numeric(self.validation_data_frame['category'])\n",
        "      # 2, 3, 8\n",
        "\n",
        "      print(len(self.train_data_frame), len(self.validation_data_frame))\n",
        "      print(self.train_data_frame.index.sort_values(), self.validation_data_frame.index.sort_values(), sep='\\n')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqERqru-ximi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "f10c8b56-b31f-4473-83c8-6f666fedfb43"
      },
      "source": [
        "# curRaw_category = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/labelMst.txt\", sep='\\t')\n",
        "# len(curRaw_category)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3407c2ab86a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# curRaw_category = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/labelMst.txt\", sep='\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurRaw_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'curRaw_category' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5osKIyL5r6tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "97fbb8cb-316d-4a22-e874-3cf2f71250ce"
      },
      "source": [
        "load_data_obj = LoadingData()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3619 106\n",
            "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
            "            ...\n",
            "            3715, 3716, 3717, 3718, 3719, 3720, 3721, 3722, 3723, 3724],\n",
            "           dtype='int64', length=3619)\n",
            "Int64Index([ 607,  732,  733,  855,  856,  857,  858,  859,  860,  861,\n",
            "            ...\n",
            "            3630, 3631, 3632, 3633, 3634, 3635, 3636, 3673, 3678, 3679],\n",
            "           dtype='int64', length=106)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPLqxPPi3jIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50a36f1a-c63d-4a37-dd5b-9cb98030feef"
      },
      "source": [
        "len(load_data_obj.cat_to_intent)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAWLSI0Dr6wR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "150f9823-3d18-4372-a693-0d33d6e78adb"
      },
      "source": [
        "print(\"전체 데이터 수 : \", len(load_data_obj.train_data_frame))\n",
        "load_data_obj.train_data_frame['category'].value_counts().sort_index()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 수 :  3619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     259\n",
              "2     231\n",
              "3     222\n",
              "4     171\n",
              "5     141\n",
              "6     144\n",
              "7     126\n",
              "8     117\n",
              "9     115\n",
              "10    118\n",
              "11    114\n",
              "12    114\n",
              "13    107\n",
              "14    108\n",
              "15    102\n",
              "16     91\n",
              "17     90\n",
              "18     89\n",
              "19     77\n",
              "20     79\n",
              "21     75\n",
              "22     72\n",
              "23     65\n",
              "24     60\n",
              "25     57\n",
              "26     58\n",
              "27     43\n",
              "28     38\n",
              "29     36\n",
              "30     33\n",
              "31     35\n",
              "32     34\n",
              "33     32\n",
              "34     32\n",
              "35     25\n",
              "36     27\n",
              "37     27\n",
              "38     25\n",
              "39     24\n",
              "40     24\n",
              "41     21\n",
              "42     19\n",
              "43     18\n",
              "44     18\n",
              "45     18\n",
              "46     15\n",
              "47     14\n",
              "48     13\n",
              "49     11\n",
              "50     10\n",
              "51      9\n",
              "52      9\n",
              "53      7\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViIYkWhOr6zb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "ea9e0bb8-2af8-4c56-f754-7e0ac0664f03"
      },
      "source": [
        "print(\"전체 데이터 수 : \", len(load_data_obj.validation_data_frame))\n",
        "load_data_obj.validation_data_frame['category'].value_counts().sort_index()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 수 :  106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     17\n",
              "2      7\n",
              "3      1\n",
              "4      2\n",
              "5     10\n",
              "6      1\n",
              "7      4\n",
              "8      6\n",
              "9      6\n",
              "10     2\n",
              "11     3\n",
              "13     5\n",
              "14     1\n",
              "15     3\n",
              "16     3\n",
              "17     3\n",
              "18     1\n",
              "19     6\n",
              "22     1\n",
              "23     5\n",
              "24     1\n",
              "25     2\n",
              "29     1\n",
              "30     3\n",
              "33     1\n",
              "34     1\n",
              "35     5\n",
              "36     1\n",
              "41     1\n",
              "43     1\n",
              "47     1\n",
              "49     1\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x6WS87Hr62X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertModel(object):\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        self.max_len = 128\n",
        "        # bert_path = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
        "        bert_path = \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\"\n",
        "        FullTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "        \n",
        "        self.bert_module = hub.KerasLayer(bert_path,trainable=True)\n",
        "\n",
        "        self.vocab_file = self.bert_module.resolved_object.vocab_file.asset_path.numpy()\n",
        "\n",
        "        # self.do_lower_case = self.bert_module.resolved_object.do_lower_case.numpy()\n",
        "        self.do_lower_case = False\n",
        "        self.tokenizer = FullTokenizer(self.vocab_file,self.do_lower_case)\n",
        "        \n",
        "    def get_masks(self,tokens, max_seq_length):\n",
        "        return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "    def get_segments(self,tokens, max_seq_length):\n",
        "        \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "        segments = []\n",
        "        current_segment_id = 0\n",
        "        for token in tokens:\n",
        "            segments.append(current_segment_id)\n",
        "            if token == \"[SEP]\":\n",
        "                current_segment_id = 1\n",
        "        return segments + [0] * (max_seq_length - len(tokens))\n",
        "    \n",
        "    def get_ids(self,tokens, tokenizer, max_seq_length):\n",
        "        \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "        token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "        input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "        return input_ids\n",
        "    def create_single_input(self,sentence,maxlen):\n",
        "\n",
        "        stokens = self.tokenizer.tokenize(sentence)\n",
        "\n",
        "        stokens = stokens[:maxlen]\n",
        "\n",
        "        stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "        ids = self.get_ids(stokens, self.tokenizer, self.max_len)\n",
        "        masks = self.get_masks(stokens, self.max_len)\n",
        "        segments = self.get_segments(stokens, self.max_len)\n",
        "        input_data = [ids,masks,segments]\n",
        "\n",
        "        return input_data\n",
        "\n",
        "    def create_input_array(self,sentences):\n",
        "        \n",
        "        input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "        for sentence in tqdm(sentences,position=0, leave=True):\n",
        "            ids,masks,segments=self.create_single_input(sentence,self.max_len-2)\n",
        "\n",
        "            input_ids.append(ids)\n",
        "            input_masks.append(masks)\n",
        "            input_segments.append(segments)\n",
        "            \n",
        "        input_array = [np.asarray(input_ids, dtype=np.int32), \n",
        "                np.asarray(input_masks, dtype=np.int32), \n",
        "                np.asarray(input_segments, dtype=np.int32)]\n",
        "        return input_array"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwwhBgJFr65O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreprocessingBertData():\n",
        "    def prepare_data_x(self,train_sentences):\n",
        "      x = bert_model_obj.create_input_array(train_sentences)\n",
        "      return x\n",
        "    \n",
        "    def prepare_data_y(self,train_labels):\n",
        "        y = list()\n",
        "        for item in train_labels:\n",
        "            label = item\n",
        "            y.append(label)\n",
        "        y = np.array(y)\n",
        "        return y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_whE9kOsGl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model_obj = BertModel()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFTlrXk2sGo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessInputLabels_func(data_frame):\n",
        "  sentences = data_frame[\"query\"].tolist()\n",
        "  labels = data_frame[\"category\"].tolist()\n",
        "\n",
        "  preprocess_bert_data_obj = PreprocessingBertData()\n",
        "  x = preprocess_bert_data_obj.prepare_data_x(sentences)\n",
        "  y = preprocess_bert_data_obj.prepare_data_y(labels)\n",
        "\n",
        "  input_ids, input_masks, segment_ids = x\n",
        "  labels = y\n",
        "\n",
        "  return [input_ids, input_masks, segment_ids] , labels"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1BGUCn2sGsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DtZmu2AsGxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DesignModel():\n",
        "    def __init__(self):\n",
        "        self.model = None        \n",
        "        self.train_data, self.train_labels = preprocessInputLabels_func(load_data_obj.train_data_frame)\n",
        "        self.validation_data, self.validation_labels = preprocessInputLabels_func(load_data_obj.validation_data_frame)\n",
        "        \n",
        "    def bert_model(self,max_seq_length): \n",
        "\n",
        "        in_id = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_ids\")\n",
        "        in_mask = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_masks\")\n",
        "        in_segment = Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "        bert_inputs = [in_id, in_mask, in_segment]\n",
        "        bert_pooled_output, bert_sequence_output = bert_model_obj.bert_module(bert_inputs)\n",
        "        bert_output = tf.keras.layers.GlobalAveragePooling1D()(bert_sequence_output)\n",
        "        # bert_output = tf.keras.layers.Dropout(0.5)(bert_output)\n",
        "        # bert_output = tf.keras.layers.Dropout(0.2)(bert_output) # ori\n",
        "        \n",
        "        # bert_outputs = tf.keras.layers.Dense(len(load_data_obj.cat_to_intent), /activation=\"softmax\", name=\"dense_output\")(bert_output)\n",
        "        \n",
        "        # bert_output = tf.keras.layers.Dense(1, activation=\"softmax\")(bert_sequence_output)\n",
        "        # bert_outputs = tf.keras.layers.Dense(1, activation=\"softmax\")(bert_output)\n",
        "        # bert_outputs = tf.keras.layers.Dense(len(load_data_obj.cat_to_intent), activation=\"softmax\", name=\"dense_output\")(bert_output)\n",
        "\n",
        "        bert_output = tf.keras.layers.Dense(128, activation=\"relu\", name=\"dense_hidden_1st\")(bert_output)\n",
        "        bert_output = tf.keras.layers.Dropout(0.5)(bert_output)\n",
        "        bert_outputs = tf.keras.layers.Dense(len(load_data_obj.cat_to_intent)+1, activation=\"softmax\", name=\"dense_output\")(bert_output)\n",
        "\n",
        "        self.model = tf.keras.models.Model(inputs=bert_inputs, outputs=bert_outputs)\n",
        "        \n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                           metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
        "        '''\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(5e-5),\n",
        "                           loss = 'binary_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "        '''\n",
        "        # Batch size: 16, 32 Learning rage (Adam): 5e-5, 3e-5, 2e-5\n",
        "        self.model.summary()\n",
        "    \n",
        "    def model_train(self,batch_size,num_epoch):\n",
        "        print(\"Fitting to model\")\n",
        "        # class_weights = class_weight.compute_class_weight('balanced', np.unique(self.train_labels), self.train_labels)\n",
        "        # es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "        checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/model_200811.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "        self.model.fit(self.train_data,self.train_labels,epochs=num_epoch,batch_size=batch_size, validation_data = (self.validation_data, self.validation_labels), callbacks=[checkpointer], verbose=1, shuffle=True)\n",
        "        print(\"Model Training complete.\")\n",
        "# , callbacks=[checkpointer], verbose=1, shuffle=True\n",
        "    def save_model(self,model,model_name):    \n",
        "        self.model.save(model_name+\".h5\")\n",
        "        print(\"Model saved to Model folder.\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNFXRy0hr68J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83aa339c-cd4d-48dc-ce8b-4599c33f2faf"
      },
      "source": [
        "# start = time.time()\n",
        "model_obj = DesignModel()\n",
        "model_obj.bert_model(bert_model_obj.max_len)\n",
        "# model_obj.model_train(16,30)\n",
        "model_obj.model_train(32, 30)\n",
        "# 1/2 loss: 3.4101 - acc: 0.1735 - val_loss: 2.3932 - val_acc: 0.4340\n",
        "# 2/2 loss: 2.0580 - acc: 0.5162 - val_loss: 1.7275 - val_acc: 0.6038"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3619/3619 [00:00<00:00, 11181.40it/s]\n",
            "100%|██████████| 106/106 [00:00<00:00, 8072.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 177853441   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 768)          0           keras_layer[2][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_hidden_1st (Dense)        (None, 128)          98432       global_average_pooling1d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128)          0           dense_hidden_1st[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_output (Dense)            (None, 54)           6966        dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 177,958,839\n",
            "Trainable params: 177,958,838\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n",
            "Fitting to model\n",
            "Epoch 1/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 2.6744 - acc: 0.4109\n",
            "Epoch 00001: val_acc improved from -inf to 0.62264, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 128s 1s/step - loss: 2.6744 - acc: 0.4109 - val_loss: 1.7234 - val_acc: 0.6226\n",
            "Epoch 2/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 1.7211 - acc: 0.6375\n",
            "Epoch 00002: val_acc improved from 0.62264 to 0.66038, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 124s 1s/step - loss: 1.7211 - acc: 0.6375 - val_loss: 1.4925 - val_acc: 0.6604\n",
            "Epoch 3/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 1.2967 - acc: 0.7198\n",
            "Epoch 00003: val_acc improved from 0.66038 to 0.71698, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 126s 1s/step - loss: 1.2967 - acc: 0.7198 - val_loss: 1.3142 - val_acc: 0.7170\n",
            "Epoch 4/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 1.0330 - acc: 0.7754\n",
            "Epoch 00004: val_acc improved from 0.71698 to 0.80189, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 124s 1s/step - loss: 1.0330 - acc: 0.7754 - val_loss: 1.2457 - val_acc: 0.8019\n",
            "Epoch 5/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.8492 - acc: 0.8221\n",
            "Epoch 00005: val_acc did not improve from 0.80189\n",
            "114/114 [==============================] - 99s 866ms/step - loss: 0.8492 - acc: 0.8221 - val_loss: 1.0033 - val_acc: 0.8019\n",
            "Epoch 6/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.7004 - acc: 0.8466\n",
            "Epoch 00006: val_acc improved from 0.80189 to 0.81132, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 128s 1s/step - loss: 0.7004 - acc: 0.8466 - val_loss: 1.1320 - val_acc: 0.8113\n",
            "Epoch 7/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.6083 - acc: 0.8685\n",
            "Epoch 00007: val_acc did not improve from 0.81132\n",
            "114/114 [==============================] - 99s 866ms/step - loss: 0.6083 - acc: 0.8685 - val_loss: 1.0872 - val_acc: 0.8113\n",
            "Epoch 8/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.4721 - acc: 0.9000\n",
            "Epoch 00008: val_acc improved from 0.81132 to 0.82075, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 128s 1s/step - loss: 0.4721 - acc: 0.9000 - val_loss: 0.8993 - val_acc: 0.8208\n",
            "Epoch 9/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.5314 - acc: 0.8839\n",
            "Epoch 00009: val_acc improved from 0.82075 to 0.83962, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 128s 1s/step - loss: 0.5314 - acc: 0.8839 - val_loss: 0.8370 - val_acc: 0.8396\n",
            "Epoch 10/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.3562 - acc: 0.9226\n",
            "Epoch 00010: val_acc did not improve from 0.83962\n",
            "114/114 [==============================] - 99s 866ms/step - loss: 0.3562 - acc: 0.9226 - val_loss: 0.8106 - val_acc: 0.8396\n",
            "Epoch 11/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.3124 - acc: 0.9348\n",
            "Epoch 00011: val_acc did not improve from 0.83962\n",
            "114/114 [==============================] - 100s 874ms/step - loss: 0.3124 - acc: 0.9348 - val_loss: 0.7485 - val_acc: 0.8396\n",
            "Epoch 12/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.2511 - acc: 0.9486\n",
            "Epoch 00012: val_acc improved from 0.83962 to 0.84906, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 129s 1s/step - loss: 0.2511 - acc: 0.9486 - val_loss: 0.7497 - val_acc: 0.8491\n",
            "Epoch 13/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.2223 - acc: 0.9544\n",
            "Epoch 00013: val_acc did not improve from 0.84906\n",
            "114/114 [==============================] - 99s 866ms/step - loss: 0.2223 - acc: 0.9544 - val_loss: 0.7613 - val_acc: 0.8396\n",
            "Epoch 14/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1982 - acc: 0.9594\n",
            "Epoch 00014: val_acc did not improve from 0.84906\n",
            "114/114 [==============================] - 100s 875ms/step - loss: 0.1982 - acc: 0.9594 - val_loss: 0.8174 - val_acc: 0.8396\n",
            "Epoch 15/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1899 - acc: 0.9591\n",
            "Epoch 00015: val_acc improved from 0.84906 to 0.88679, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 128s 1s/step - loss: 0.1899 - acc: 0.9591 - val_loss: 0.6272 - val_acc: 0.8868\n",
            "Epoch 16/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1602 - acc: 0.9732\n",
            "Epoch 00016: val_acc improved from 0.88679 to 0.91509, saving model to /content/drive/My Drive/model_200811.h5\n",
            "114/114 [==============================] - 127s 1s/step - loss: 0.1602 - acc: 0.9732 - val_loss: 0.5841 - val_acc: 0.9151\n",
            "Epoch 17/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1377 - acc: 0.9751\n",
            "Epoch 00017: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 99s 864ms/step - loss: 0.1377 - acc: 0.9751 - val_loss: 0.6967 - val_acc: 0.8774\n",
            "Epoch 18/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1186 - acc: 0.9776\n",
            "Epoch 00018: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 876ms/step - loss: 0.1186 - acc: 0.9776 - val_loss: 0.6427 - val_acc: 0.8962\n",
            "Epoch 19/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1315 - acc: 0.9746\n",
            "Epoch 00019: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 878ms/step - loss: 0.1315 - acc: 0.9746 - val_loss: 0.6383 - val_acc: 0.9057\n",
            "Epoch 20/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0891 - acc: 0.9829\n",
            "Epoch 00020: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 879ms/step - loss: 0.0891 - acc: 0.9829 - val_loss: 0.8463 - val_acc: 0.8585\n",
            "Epoch 21/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0823 - acc: 0.9854\n",
            "Epoch 00021: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 881ms/step - loss: 0.0823 - acc: 0.9854 - val_loss: 0.7159 - val_acc: 0.9057\n",
            "Epoch 22/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0872 - acc: 0.9856\n",
            "Epoch 00022: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 881ms/step - loss: 0.0872 - acc: 0.9856 - val_loss: 0.6464 - val_acc: 0.8962\n",
            "Epoch 23/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.1100 - acc: 0.9793\n",
            "Epoch 00023: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 880ms/step - loss: 0.1100 - acc: 0.9793 - val_loss: 0.7449 - val_acc: 0.8774\n",
            "Epoch 24/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0773 - acc: 0.9845\n",
            "Epoch 00024: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 880ms/step - loss: 0.0773 - acc: 0.9845 - val_loss: 0.8860 - val_acc: 0.8679\n",
            "Epoch 25/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0724 - acc: 0.9862\n",
            "Epoch 00025: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 881ms/step - loss: 0.0724 - acc: 0.9862 - val_loss: 0.6846 - val_acc: 0.8774\n",
            "Epoch 26/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.9820\n",
            "Epoch 00026: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 101s 884ms/step - loss: 0.0947 - acc: 0.9820 - val_loss: 0.7932 - val_acc: 0.8679\n",
            "Epoch 27/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0676 - acc: 0.9870\n",
            "Epoch 00027: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 101s 882ms/step - loss: 0.0676 - acc: 0.9870 - val_loss: 0.8170 - val_acc: 0.8679\n",
            "Epoch 28/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0527 - acc: 0.9895\n",
            "Epoch 00028: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 881ms/step - loss: 0.0527 - acc: 0.9895 - val_loss: 0.9537 - val_acc: 0.8585\n",
            "Epoch 29/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0394 - acc: 0.9931\n",
            "Epoch 00029: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 881ms/step - loss: 0.0394 - acc: 0.9931 - val_loss: 0.8409 - val_acc: 0.8774\n",
            "Epoch 30/30\n",
            "114/114 [==============================] - ETA: 0s - loss: 0.0441 - acc: 0.9920\n",
            "Epoch 00030: val_acc did not improve from 0.91509\n",
            "114/114 [==============================] - 100s 880ms/step - loss: 0.0441 - acc: 0.9920 - val_loss: 0.8454 - val_acc: 0.8868\n",
            "Model Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5PLrtf0-96Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3aca734-d6cb-4dc2-b02c-46ba76165488"
      },
      "source": [
        "..# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2OkBgBoLdgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5c1f9129-a665-4a6d-b6c6-b49785618746"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNX2n-TXo-C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "a27c49e7-9694-4798-b003-22f2bdf9ebde"
      },
      "source": [
        "# model_obj.model_train(16,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting to model\n",
            "Epoch 1/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9942\n",
            "Epoch 00001: val_loss improved from inf to 1.27346, saving model to /content/drive/My Drive/bert_model/model_best.h5\n",
            "227/227 [==============================] - 197s 868ms/step - loss: 0.0231 - acc: 0.9942 - val_loss: 1.2735 - val_acc: 0.8019\n",
            "Epoch 2/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9970\n",
            "Epoch 00002: val_loss did not improve from 1.27346\n",
            "227/227 [==============================] - 197s 868ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 1.3613 - val_acc: 0.7925\n",
            "Epoch 3/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0181 - acc: 0.9947\n",
            "Epoch 00003: val_loss improved from 1.27346 to 1.21492, saving model to /content/drive/My Drive/bert_model/model_best.h5\n",
            "227/227 [==============================] - 197s 868ms/step - loss: 0.0181 - acc: 0.9947 - val_loss: 1.2149 - val_acc: 0.8208\n",
            "Epoch 4/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0183 - acc: 0.9956\n",
            "Epoch 00004: val_loss did not improve from 1.21492\n",
            "227/227 [==============================] - 197s 868ms/step - loss: 0.0183 - acc: 0.9956 - val_loss: 1.3572 - val_acc: 0.8208\n",
            "Epoch 5/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9912\n",
            "Epoch 00005: val_loss did not improve from 1.21492\n",
            "227/227 [==============================] - 197s 866ms/step - loss: 0.0311 - acc: 0.9912 - val_loss: 1.3214 - val_acc: 0.8302\n",
            "Epoch 6/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9914\n",
            "Epoch 00006: val_loss did not improve from 1.21492\n",
            "227/227 [==============================] - 197s 870ms/step - loss: 0.0286 - acc: 0.9914 - val_loss: 1.3408 - val_acc: 0.8113\n",
            "Epoch 7/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0334 - acc: 0.9909\n",
            "Epoch 00007: val_loss improved from 1.21492 to 1.10515, saving model to /content/drive/My Drive/bert_model/model_best.h5\n",
            "227/227 [==============================] - 195s 858ms/step - loss: 0.0334 - acc: 0.9909 - val_loss: 1.1052 - val_acc: 0.8491\n",
            "Epoch 8/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0241 - acc: 0.9942\n",
            "Epoch 00008: val_loss improved from 1.10515 to 1.07634, saving model to /content/drive/My Drive/bert_model/model_best.h5\n",
            "227/227 [==============================] - 194s 855ms/step - loss: 0.0241 - acc: 0.9942 - val_loss: 1.0763 - val_acc: 0.8396\n",
            "Epoch 9/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0226 - acc: 0.9939\n",
            "Epoch 00009: val_loss did not improve from 1.07634\n",
            "227/227 [==============================] - 194s 854ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 1.2128 - val_acc: 0.8396\n",
            "Epoch 10/10\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0371 - acc: 0.9914\n",
            "Epoch 00010: val_loss did not improve from 1.07634\n",
            "227/227 [==============================] - 194s 854ms/step - loss: 0.0371 - acc: 0.9914 - val_loss: 1.2618 - val_acc: 0.8208\n",
            "Model Training complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3I29w6q4uFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37f75e86-f6c9-4208-eeff-958c8f0f63cb"
      },
      "source": [
        "model_obj.save_model(model_obj.model,\"0731_accu_84\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saved to Model folder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7EtvNr2cqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1493ebac-33d1-4744-f66d-68265afa9924"
      },
      "source": [
        "model_obj.model.save('path_to_saved_model', save_format=\"tf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: path_to_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: path_to_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTjKz9xWPyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_obj.model.save(\"/content/gdrive/My Drive/Colab Notebooks/model_sjm_200731.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkMYN6K7SuF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_obj_path = '/content/gdrive/My Drive/Colab Notebooks/model_sjm_200803.h5'\n",
        "\n",
        "new_model = load_model(model_obj_path, custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQ-ZTUjUh6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluation():\n",
        "    def get_accuracy(self,actuals, predictions):\n",
        "        acc = accuracy_score(actuals, predictions)\n",
        "        return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74IpsgDoMgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Prediction():\n",
        "    def __init__(self):\n",
        "        self.model = model_obj.model\n",
        "        \n",
        "    def predict_validation(self, data_frame):\n",
        "        valid_sentences = data_frame[\"query\"].tolist()\n",
        "        valid_labels = data_frame[\"category\"].tolist()\n",
        "\n",
        "        preprocess_bert_data_obj = PreprocessingBertData()\n",
        "        val_x = preprocess_bert_data_obj.prepare_data_x(valid_sentences)\n",
        "        prediction_labels = list(self.model.predict(val_x).argmax(axis=-1))\n",
        "        return valid_labels,prediction_labels\n",
        "        \n",
        "    \n",
        "    def predict(self,query):\n",
        "        query_seq = bert_model_obj.create_input_array([query])\n",
        "        pred = self.model.predict(query_seq)\n",
        "        pred = np.argmax(pred)\n",
        "        result = load_data_obj.intent_to_cat[str(pred)]\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMnLIFqzoQGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2241c425-210d-40de-ba5d-16b5c91eecac"
      },
      "source": [
        "print(load_data_obj.cat_to_intent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'직원일반': '4', '회계업무': '7', '강사양성과정': '41', '프로그래밍일반': '13', '소프트웨어공학': '42', '데이터분석:일반': '8', '웹/앱개발': '25', 'OS일반': '23', '데이터분석:머신러닝딥러닝': '24', '데이터베이스/프로그래밍': '17', '정보보안': '12', '금융투자신탁': '15', '법률교육과정': '26', '기업금융': '29', '경영교육과정': '3', '여신업무': '6', '내부감사': '39', 'MBA과정': '33', '세무업무': '31', '유통교육과정': '20', '최고위과정': '32', '마인드컨드롤': '38', '금융교육과정': '10', '네트워크통신': '49', '커뮤니케이션스킬': '21', '영업마케팅': '2', '프로젝트관리': '36', '블록체인': '27', 'IT실무': '28', '문서작성활용': '9', '생산품질관리': '34', '인사관리': '46', '개인역량강화': '16', '구매업무': '51', '개인고객금융업무': '11', '사물인터넷(IoT)': '48', '산업동향': '1', '리더십역량강화': '18', '농축산업교육': '14', '인문학': '44', 'RM교육': '52', '보험업무': '5', '수신업무': '53', '금융리스크': '22', '외환업무': '35', '부동산관련과정': '19', '상품기획역량': '43', '언어교육': '37', '글로벌역량교육': '45', '고객상담': '47', '건설업무': '40', '소매관리': '30', '안전관리교육': '50'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvxUy8pJoWGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_obj = Prediction()\n",
        "#pred_obj.predict_validation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vBzEnxJpe0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "querylist = load_data_obj.validation_data_frame.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuMusA5fyfv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "be87829b-13c9-4810-80c1-62de9d8db6e1"
      },
      "source": [
        "querylist[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['KBI 금융DT테스트', 'KBI 금융DT테스트', '산업동향', 1],\n",
              " ['여신심사', '(주말) 여신심사 (은행)', '여신업무', 6],\n",
              " ['토요 VIP 고객과의 소통을 위한 문화강좌', '토요 VIP 고객과의 소통을 위한 문화강좌', '개인고객금융업무', 11],\n",
              " ['직장인을 위한 실무 파워포인트 2016', '직장인을 위한 실무 파워포인트 2016(금융지주)', '문서작성활용', 9],\n",
              " ['어서와 데이터는 처음이지 기초 OF 기초 데이터 개념',\n",
              "  '어서와 데이터는 처음이지 - 기초 of 기초 데이터 개념(금융지주)',\n",
              "  '데이터분석:일반',\n",
              "  8],\n",
              " ['어서와 데이터는 처음이지 미래 예측을 위한 기초 개념',\n",
              "  '어서와 데이터는 처음이지 - 미래 예측을 위한 기초 개념(금융지주)',\n",
              "  '데이터분석:일반',\n",
              "  8],\n",
              " ['어서와 데이터는 처음이지 효과 검증을 위한 기초 개념',\n",
              "  '어서와 데이터는 처음이지 - 효과 검증을 위한 기초 개념(금융지주)',\n",
              "  '데이터분석:일반',\n",
              "  8],\n",
              " ['산업혁명 시대의 비즈니스 혁명 플랫폼을 잡아라',\n",
              "  '4차 산업혁명 시대의 비즈니스 혁명, 플랫폼을 잡아라(금융지주)',\n",
              "  '산업동향',\n",
              "  1],\n",
              " ['KIFRS Ⅱ', 'K-IFRS Ⅱ(금융지주)', '회계업무', 7],\n",
              " ['인공지능 AI 프로그래밍파이썬을 활용한 머신러닝 딥러닝 기초 다지기 PART2',\n",
              "  '인공지능(AI) 프로그래밍_파이썬을 활용한 머신러닝, 딥러닝 기초 다지기 Part.2(금융지주)',\n",
              "  '데이터분석:머신러닝딥러닝',\n",
              "  24]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT6wmu_FoV9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f5666a8-0ecb-47b2-f047-c4c85db22ab3"
      },
      "source": [
        "for query in querylist[0:50]:\n",
        "  result = pred_obj.predict(query[1])\n",
        "  # print(\"\\n■Predicted Intent: \"+str(result)+\"\\tActual Intent: \"+(load_data_obj.cat_to_intent[query[2]]))\n",
        "  # print(str(load_data_obj.intent_to_cat[str(query[3])]))\n",
        "  print(\"■ Predicted Intent: \"+str(result)+\"\\tActual Intent: \"+str(load_data_obj.intent_to_cat[str(query[3])])+\"\\tquery: \"+(query[1]), sep=\"\\n\\n\")\n",
        "  # print(\"■ Predicted Intent: \"+str(result)+\"\\tActual Intent: \"+ query[2]+\"\\tquery: \"+(query[1]), sep=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 190.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1975.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 375.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 448.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 442.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 673.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: MBA과정\tActual Intent: 산업동향\tquery: KBI 금융DT테스트\n",
            "■ Predicted Intent: 여신업무\tActual Intent: 여신업무\tquery: (주말) 여신심사 (은행)\n",
            "■ Predicted Intent: 직원일반\tActual Intent: 개인고객금융업무\tquery: 토요 VIP 고객과의 소통을 위한 문화강좌\n",
            "■ Predicted Intent: 문서작성활용\tActual Intent: 문서작성활용\tquery: 직장인을 위한 실무 파워포인트 2016(금융지주)\n",
            "■ Predicted Intent: 데이터분석:일반\tActual Intent: 데이터분석:일반\tquery: 어서와 데이터는 처음이지 - 기초 of 기초 데이터 개념(금융지주)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 421.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 493.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 3964.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 655.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 데이터분석:일반\tActual Intent: 데이터분석:일반\tquery: 어서와 데이터는 처음이지 - 미래 예측을 위한 기초 개념(금융지주)\n",
            "■ Predicted Intent: 데이터분석:일반\tActual Intent: 데이터분석:일반\tquery: 어서와 데이터는 처음이지 - 효과 검증을 위한 기초 개념(금융지주)\n",
            "■ Predicted Intent: 산업동향\tActual Intent: 산업동향\tquery: 4차 산업혁명 시대의 비즈니스 혁명, 플랫폼을 잡아라(금융지주)\n",
            "■ Predicted Intent: 회계업무\tActual Intent: 회계업무\tquery: K-IFRS Ⅱ(금융지주)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1151.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1014.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 503.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 589.83it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 3802.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 데이터분석:머신러닝딥러닝\tActual Intent: 데이터분석:머신러닝딥러닝\tquery: 인공지능(AI) 프로그래밍_파이썬을 활용한 머신러닝, 딥러닝 기초 다지기 Part.2(금융지주)\n",
            "■ Predicted Intent: 산업동향\tActual Intent: 산업동향\tquery: (농축협)클라우드로 성장하는 기업들\n",
            "■ Predicted Intent: OS일반\tActual Intent: OS일반\tquery: (농축협)비즈니스 핵심 경쟁력! 클라우드 활용 체크포인트\n",
            "■ Predicted Intent: 개인역량강화\tActual Intent: 산업동향\tquery: (농축협)주 52시간 시대 해법! 로보틱 처리 자동화(RPA)\n",
            "■ Predicted Intent: 부동산관련과정\tActual Intent: 부동산관련과정\tquery: (농축협)부동산 경매와 권리분석\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 460.91it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2734.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 516.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 496.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 부동산관련과정\tActual Intent: 부동산관련과정\tquery: (농축협)부동산 권리분석\n",
            "■ Predicted Intent: 산업동향\tActual Intent: 산업동향\tquery: 디지털 금융\n",
            "■ Predicted Intent: 농축산업교육\tActual Intent: 농축산업교육\tquery: e-러닝(스마트팜축산)\n",
            "■ Predicted Intent: 외환업무\tActual Intent: 외환업무\tquery: 쉽게 배우는 농?축협 외국환 실무\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 3113.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 464.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1353.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1331.10it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [농_마트]유통사업장 CS 베이직\n",
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [하_마트]유통사업장 CS 베이직\n",
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [농]하나로마트 CS 베이직\n",
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [하]하나로마트 CS 베이직\n",
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [농_마트]하나로마트 마트마케팅 아카데미\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 245.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2368.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 3313.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 449.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2418.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 영업마케팅\tActual Intent: 영업마케팅\tquery: [하_마트]하나로마트 마트마케팅 아카데미\n",
            "■ Predicted Intent: 소매관리\tActual Intent: 소매관리\tquery: 하나로마트 마트관리자 능력향상\n",
            "■ Predicted Intent: 소매관리\tActual Intent: 소매관리\tquery: [농_마트]하나로마트 마트전산 아카데미\n",
            "■ Predicted Intent: 소매관리\tActual Intent: 소매관리\tquery: [하_마트]하나로마트 마트전산 아카데미\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 450.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 419.72it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 503.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 941.91it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 산업동향\tActual Intent: 산업동향\tquery: 4차 산업혁명과 뉴칼라[비즈니스 생존전략]\n",
            "■ Predicted Intent: 문서작성활용\tActual Intent: 문서작성활용\tquery: 직장인을 위한 실무 파워포인트 2016\n",
            "■ Predicted Intent: 문서작성활용\tActual Intent: 문서작성활용\tquery: 직장인을 위한 실무 엑셀 2016_데이터 분석 입문\n",
            "■ Predicted Intent: 강사양성과정\tActual Intent: 강사양성과정\tquery: IT 사내강사 양성과정\n",
            "■ Predicted Intent: MBA과정\tActual Intent: MBA과정\tquery: 국민대 AI 빅데이터 MBA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 228.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1183.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1204.22it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 436.54it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1026.25it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1453.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 외환업무\tActual Intent: 외환업무\tquery: 외환전문역(Ⅱ종)양성 최종정리 과정\n",
            "■ Predicted Intent: 외환업무\tActual Intent: 외환업무\tquery: 외환전문역(Ⅱ종)양성 종합 과정\n",
            "■ Predicted Intent: 금융투자신탁\tActual Intent: 회계업무\tquery: 전문사모운용사 백오피스(펀드세무회계)\n",
            "■ Predicted Intent: 프로젝트관리\tActual Intent: 프로젝트관리\tquery: 이론과 실전의 PM 전문가!프로젝트 관리 한판승[스마트러닝]\n",
            "■ Predicted Intent: 프로그래밍일반\tActual Intent: 프로그래밍일반\tquery: 빅데이터를 위한 파이썬\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 453.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 508.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1767.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 467.07it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 데이터베이스/프로그래밍\tActual Intent: 데이터베이스/프로그래밍\tquery: Elasticsearch Engineer\n",
            "■ Predicted Intent: 웹/앱개발\tActual Intent: 웹/앱개발\tquery: 업무에 바로 쓰는 HTML5와 CSS3\n",
            "■ Predicted Intent: 프로그래밍일반\tActual Intent: 프로그래밍일반\tquery: Java Framework - Spring, iBatis, MyBatis 연동\n",
            "■ Predicted Intent: 웹/앱개발\tActual Intent: 웹/앱개발\tquery: Swift Programming\n",
            "■ Predicted Intent: 프로그래밍일반\tActual Intent: 프로그래밍일반\tquery: 파이썬 핵심\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 816.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 497.90it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 415.81it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 495.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1914.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 1471.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: 프로그래밍일반\tActual Intent: 프로그래밍일반\tquery: Spring Framework를 활용한 OpenAPI 서비스 개발\n",
            "■ Predicted Intent: 데이터분석:일반\tActual Intent: 데이터분석:일반\tquery: [Big Data]R을 활용한 빅데이터 분석 및 활용실무\n",
            "■ Predicted Intent: OS일반\tActual Intent: OS일반\tquery: AWS로 시작하는 클라우드 컴퓨팅(참고도서제공)[스마트러닝]\n",
            "■ Predicted Intent: 데이터분석:일반\tActual Intent: 데이터분석:일반\tquery: 데이터분석준전문가(ADsP)_데이터의 이해(참고도서제공)[스마트러닝]\n",
            "■ Predicted Intent: 개인고객금융업무\tActual Intent: 네트워크통신\tquery: 쉽게 배우는 시스코랜스위칭(참고도서제공)[스마트러닝]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 389.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 525.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "■ Predicted Intent: OS일반\tActual Intent: OS일반\tquery: Perfect! 클라우드 데이터센터 핵심 기술 실무\n",
            "■ Predicted Intent: 데이터베이스/프로그래밍\tActual Intent: 데이터베이스/프로그래밍\tquery: Oracle Database 12c: SQL Tuning Workshop & Case Study\n",
            "■ Predicted Intent: 데이터베이스/프로그래밍\tActual Intent: 데이터베이스/프로그래밍\tquery: Oracle Database: Performance Management and Tuning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkUg9mf0NE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dc1957be-d501-4eae-9a09-ce683959a233"
      },
      "source": [
        "rawTrain_df[\"train/test\"] = \"train\"\n",
        "rawTest_df[\"train/test\"] = \"test\"\n",
        "\n",
        "ytrain,predicted_ml_train = pred_obj.predict_validation(load_data_obj.train_data_frame)\n",
        "ytest,predicted_ml_test = pred_obj.predict_validation(load_data_obj.validation_data_frame)\n",
        "\n",
        "result_train = pd.concat([rawTrain_df.reset_index(), pd.Series(predicted_ml_train, name=\"Result\")], axis=1)\n",
        "result_test = pd.concat([rawTest_df.reset_index(), pd.Series(predicted_ml_test, name=\"Result\")], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3619/3619 [00:00<00:00, 10804.02it/s]\n",
            "100%|██████████| 106/106 [00:00<00:00, 9367.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5gC9OMjQeST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "5fccdff6-e6dd-4b88-cc87-74d502ee9b4c"
      },
      "source": [
        "curRaw_df_result = pd.merge(curRaw_df.reset_index(), pd.concat(\n",
        "        [result_test[['index', 'train/test', 'Result']], result_train[['index', 'train/test', 'Result']]],\n",
        "        ignore_index=True), on='index')\n",
        "curRaw_df_result = curRaw_df_result.astype({'Result': 'str'})\n",
        "curRaw_df_result[\"hitYN\"] = curRaw_df_result[labelCol_char] == curRaw_df_result[\"Result\"]\n",
        "curRaw_category = curRaw_df[['STD_CAT', 'STD_CD']].drop_duplicates(['STD_CAT'])\n",
        "cd_to_cat = curRaw_category.set_index('STD_CD').T.to_dict('records')[0]\n",
        "# cd_to_cat = {int(k):v for k, v in cd_to_cat.items()}\n",
        "curRaw_df_result['Result_CAT'] = curRaw_df_result['Result'].replace(cd_to_cat)\n",
        "display(curRaw_df_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>CRSE_CD</th>\n",
              "      <th>CRSE_NM</th>\n",
              "      <th>CRSE_BERT</th>\n",
              "      <th>CRSE_CL</th>\n",
              "      <th>PADDED_NM</th>\n",
              "      <th>CRT_YM</th>\n",
              "      <th>STD_CAT</th>\n",
              "      <th>STD_CD</th>\n",
              "      <th>train/test</th>\n",
              "      <th>Result</th>\n",
              "      <th>hitYN</th>\n",
              "      <th>Result_CAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AAAA009</td>\n",
              "      <td>(중앙회)5급신규직원입문과정(직무)</td>\n",
              "      <td>신규직원입문 직무</td>\n",
              "      <td>[신규, 직원, 입문, 직무]</td>\n",
              "      <td>[79, 71, 97, 153, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2018.12</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>직원일반</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AABA096</td>\n",
              "      <td>하나로유통 세무회계 실무</td>\n",
              "      <td>하나로유통 세무회계 실무</td>\n",
              "      <td>[하나, 로, 유통, 세무, 회계, 실무]</td>\n",
              "      <td>[195, 29, 44, 90, 61, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2017.04</td>\n",
              "      <td>회계업무</td>\n",
              "      <td>7</td>\n",
              "      <td>train</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>회계업무</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AABA097</td>\n",
              "      <td>협동조합전문가역량강화과정</td>\n",
              "      <td>협동조합전문가역량강화</td>\n",
              "      <td>[협동조합, 전문가, 역량, 강화]</td>\n",
              "      <td>[344, 19, 91, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2018.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>직원일반</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AAPA010</td>\n",
              "      <td>농축협 순회검사역 과정</td>\n",
              "      <td>농축협 순회검사역 과정</td>\n",
              "      <td>[농, 축협, 순회, 검사역, 과정]</td>\n",
              "      <td>[8, 26, 2475, 1390, 50, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>직원일반</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AD3A001</td>\n",
              "      <td>(생명) 직무전문가 육성체계 및 교육프로그램 사례발표회</td>\n",
              "      <td>직무전문가 육성체계 및 교육프로그램 사례발표회</td>\n",
              "      <td>[직무, 전문가, 육성, 체계, 및, 교육, 프로그램, 사례, 발표회]</td>\n",
              "      <td>[153, 19, 715, 762, 15, 9, 738, 65, 891, 0, 0,...</td>\n",
              "      <td>2018.04</td>\n",
              "      <td>강사양성과정</td>\n",
              "      <td>41</td>\n",
              "      <td>train</td>\n",
              "      <td>41</td>\n",
              "      <td>True</td>\n",
              "      <td>강사양성과정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>3720</td>\n",
              "      <td>LSDM001</td>\n",
              "      <td>상호금융 리더를 위한 DT-AI 인사이트</td>\n",
              "      <td>상호금융 리더를 위한 DTAI 인사이트</td>\n",
              "      <td>[상호, 금융, 리더, 를, 위한, DTAI, 인, 사이트]</td>\n",
              "      <td>[186, 7, 72, 12, 13, 3429, 83, 847, 0, 0, 0, 0...</td>\n",
              "      <td>2019.08</td>\n",
              "      <td>산업동향</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>산업동향</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3721</th>\n",
              "      <td>3721</td>\n",
              "      <td>LSPM001</td>\n",
              "      <td>빅데이터를 활용한 CRM고객관리</td>\n",
              "      <td>빅데이터를 활용한 CRM고객관리</td>\n",
              "      <td>[빅, 데이터, 를, 활용, 한, CRM, 고객, 관리]</td>\n",
              "      <td>[128, 63, 12, 28, 22, 379, 42, 11, 0, 0, 0, 0,...</td>\n",
              "      <td>2019.05</td>\n",
              "      <td>영업마케팅</td>\n",
              "      <td>2</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>영업마케팅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3722</th>\n",
              "      <td>3722</td>\n",
              "      <td>LTBK001</td>\n",
              "      <td>재무리스크 측정과 관리실무</td>\n",
              "      <td>재무리스크 측정과 관리실무</td>\n",
              "      <td>[재무, 리스크, 측정, 과, 관리, 실무]</td>\n",
              "      <td>[88, 147, 1145, 21, 11, 4, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2019.10</td>\n",
              "      <td>금융리스크</td>\n",
              "      <td>22</td>\n",
              "      <td>train</td>\n",
              "      <td>22</td>\n",
              "      <td>True</td>\n",
              "      <td>금융리스크</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3723</th>\n",
              "      <td>3723</td>\n",
              "      <td>LTDK001</td>\n",
              "      <td>북한비즈니스</td>\n",
              "      <td>북한비즈니스</td>\n",
              "      <td>[북한, 비즈니스]</td>\n",
              "      <td>[2968, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>2020.04</td>\n",
              "      <td>금융교육과정</td>\n",
              "      <td>10</td>\n",
              "      <td>train</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>금융교육과정</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3724</th>\n",
              "      <td>3724</td>\n",
              "      <td>LUPD001</td>\n",
              "      <td>영업점관리자 사이버교육</td>\n",
              "      <td>영업점관리자 사이버교육</td>\n",
              "      <td>[영업, 점, 관리자, 사이버, 교육]</td>\n",
              "      <td>[104, 230, 100, 151, 9, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>2020.03</td>\n",
              "      <td>직원일반</td>\n",
              "      <td>4</td>\n",
              "      <td>train</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>직원일반</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3725 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  CRSE_CD                         CRSE_NM  ... Result hitYN Result_CAT\n",
              "0         0  AAAA009             (중앙회)5급신규직원입문과정(직무)  ...      4  True       직원일반\n",
              "1         1  AABA096                   하나로유통 세무회계 실무  ...      7  True       회계업무\n",
              "2         2  AABA097                   협동조합전문가역량강화과정  ...      4  True       직원일반\n",
              "3         3  AAPA010                    농축협 순회검사역 과정  ...      4  True       직원일반\n",
              "4         4  AD3A001  (생명) 직무전문가 육성체계 및 교육프로그램 사례발표회  ...     41  True     강사양성과정\n",
              "...     ...      ...                             ...  ...    ...   ...        ...\n",
              "3720   3720  LSDM001          상호금융 리더를 위한 DT-AI 인사이트  ...      1  True       산업동향\n",
              "3721   3721  LSPM001               빅데이터를 활용한 CRM고객관리  ...      2  True      영업마케팅\n",
              "3722   3722  LTBK001                  재무리스크 측정과 관리실무  ...     22  True      금융리스크\n",
              "3723   3723  LTDK001                          북한비즈니스  ...     10  True     금융교육과정\n",
              "3724   3724  LUPD001                    영업점관리자 사이버교육  ...      4  True       직원일반\n",
              "\n",
              "[3725 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6mdk-lfmJez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#파일저장\n",
        "curRaw_df_result.to_csv(\"curRaw_df_result_0803.csv\", index = False, encoding=\"UTF-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "223JQeCJoaPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7205fb61-e47a-40a0-ce22-7847647836f6"
      },
      "source": [
        "eval_obj = Evaluation()\n",
        "ytest,ypred = pred_obj.predict_validation(load_data_obj.validation_data_frame)\n",
        "acc = eval_obj.get_accuracy(ytest,ypred)\n",
        "print(\"Auc: {:.2%}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 106/106 [00:00<00:00, 5311.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Auc: 83.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtxyMjavZga-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "d95a6cd6-695c-4b7b-c815-4e13c83c6b21"
      },
      "source": [
        "tensorflowjs.converters.convert_tf_saved_model(model_obj.model, '/content/drive/My Drive/bert')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-5e467186a591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorflowjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tf_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/bert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\u001b[0m in \u001b[0;36mconvert_tf_saved_model\u001b[0;34m(saved_model_dir, output_dir, signature_def, saved_model_tags, quantization_dtype_map, skip_op_check, strip_debug_ops, weight_shard_size_bytes, control_flow_v2)\u001b[0m\n\u001b[1;32m    467\u001b[0m   \u001b[0;31m# Ensure any graphs created in eager mode are able to run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m   \u001b[0m_check_signature_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \"\"\"\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 588\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   debug_info_path = os.path.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;31m# Build the path to the SavedModel in pbtxt format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   path_to_pbtxt = os.path.join(\n\u001b[0;32m---> 86\u001b[0;31m       \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m       compat.as_bytes(constants.SAVED_MODEL_FILENAME_PBTXT))\n\u001b[1;32m     88\u001b[0m   \u001b[0;31m# Build the path to the SavedModel in pb format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 87\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <tensorflow.python.keras.engine.training.Model object at 0x7ff35052dd68>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ELdqKl3ve7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f29be266-a47f-4bd5-9fdf-9de97860d178"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "hub_url = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
        "embed = hub.KerasLayer(hub_url)\n",
        "embeddings = embed([\"A long sentence.\", \"single-word\", \"http://example.com\"])\n",
        "print(embeddings.shape, embeddings.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 128) <dtype: 'float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xba9DjYssj17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkC-PJWXz1qU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1d32b1ee-3531-427b-c821-e36ec8498115"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iJvrIwF6gqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model structure to JSON (no weights)\n",
        "model_json = model_obj.model.to_json()\n",
        "with open(\"model_to_json.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# saving the model weight separately\n",
        "model_obj.model.save_weights(\"/content/drive/My Drive/bert/j_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0ejzWXavt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffdb0881-7743-4788-b9b4-a3d06390fd1c"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/07/1e1da0d87f0cd1e3e3b6fa20ac4ceca43318d9ba10d49206c49dbd2816f2/tensorflowjs-2.0.1.post1-py3-none-any.whl (60kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting PyInquirer==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.18.5)\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Collecting tensorflow-cpu<3,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/4f/7bf91c87907873177ad99a31014fb77271a693a3a7cb75e522ac6b556416/tensorflow_cpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (144.4MB)\n",
            "\u001b[K     |████████████████████████████████| 144.4MB 97kB/s \n",
            "\u001b[?25hCollecting prompt_toolkit==1.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 43.3MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl (914kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2016.11.21 in /usr/local/lib/python3.6/dist-packages (from PyInquirer==1.0.3->tensorflowjs) (2019.12.20)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0->tensorflowjs) (3.12.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0->tensorflowjs) (49.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Building wheels for collected packages: PyInquirer\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32851 sha256=b1a5ccd01d2bdb83374f0076fce5a6f7680c3af46b98411f4f5e27eb09068d54\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "Successfully built PyInquirer\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit, Pygments, PyInquirer, tensorflow-hub, tensorflow-cpu, tensorflowjs\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: tensorflow-hub 0.8.0\n",
            "    Uninstalling tensorflow-hub-0.8.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.8.0\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.6.1 prompt-toolkit-1.0.14 tensorflow-cpu-2.2.0 tensorflow-hub-0.7.0 tensorflowjs-2.0.1.post1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit",
                  "pygments",
                  "tensorflow",
                  "tensorflow_hub"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APy7m5F-ayQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgXXqOmFwPjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model_obj.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiiGg_0J3mFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --input_format keras bert.h5 model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3JhdRAe4Adh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "987fa5b8-d17a-4a91-d734-280664c8bd07"
      },
      "source": [
        "!tensorflowjs_converter --input_format keras --output_format tfjs_layers_model bert.json model/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorflowjs_converter\", line 8, in <module>\n",
            "    sys.exit(pip_main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/converter.py\", line 735, in pip_main\n",
            "    main([' '.join(sys.argv[1:])])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/converter.py\", line 739, in main\n",
            "    convert(argv[0].split(' '))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/converter.py\", line 654, in convert\n",
            "    weight_shard_size_bytes=weight_shard_size_bytes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/converter.py\", line 74, in dispatch_keras_h5_to_tfjs_layers_model_conversion\n",
            "    raise ValueError('Nonexistent path to HDF5 file: %s' % h5_path)\n",
            "ValueError: Nonexistent path to HDF5 file: bert.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "697a4A2ObHJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}